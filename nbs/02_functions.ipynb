{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection\n",
    "\n",
    "> Helps Manage Snowflake Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from __future__ import annotations\n",
    "from customfunctions.common import print_hello\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col, sum, avg, count, to_char, current_timestamp\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def hello_function(name: str) -> str:\n",
    "    return print_hello(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def perform_aggregation(session: Session, aggregation_request: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs data aggregation based on the provided aggregation request.\n",
    "\n",
    "    This function takes a Snowflake session and an aggregation request in JSON format,\n",
    "    applies the specified filters, groups the data, calculates the requested metrics,\n",
    "    and saves the results to a target table in Snowflake.\n",
    "\n",
    "    Parameters\n",
    "    session : snowflake.snowpark.Session\n",
    "        An active Snowflake session object.\n",
    "    aggregation_request : str\n",
    "        A JSON string containing the aggregation specifications. It should include:\n",
    "        - source_table: Name of the source table in Snowflake.\n",
    "        - target_table: Name of the table where results will be saved.\n",
    "        - group_by: List of columns to group by.\n",
    "        - metrics: List of metrics to calculate, each with a name, function, and column.\n",
    "        - filters: List of filters to apply to the data.\n",
    "\n",
    "    The aggregation_request should have the following structure:\n",
    "        - TODO: Think about fine grain control, but for now you can have \n",
    "                <database>.<schema>.<table> and if the caller has access\n",
    "                then it will work correctly.\n",
    "    {\n",
    "        \"source_table\": str,\n",
    "        \"target_table\": str,\n",
    "        \"group_by\": List[str],\n",
    "        \"metrics\": List[Dict[str, str]],\n",
    "        \"filters\": List[Dict[str, Union[str, List[str]]]]\n",
    "    }\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        The function doesn't return a value, but it prints a confirmation message\n",
    "        and saves the results to the specified target table in Snowflake.\n",
    "    \"\"\"\n",
    "\n",
    "    request = json.loads(aggregation_request)\n",
    "    \n",
    "    df = session.table(request['source_table'])\n",
    "    for filter in request['filters']:\n",
    "        if filter['operator'] == 'between':\n",
    "            df = df.filter((col(filter['column']) >= filter['value'][0]) & \n",
    "                           (col(filter['column']) <= filter['value'][1]))\n",
    "        elif filter['operator'] == 'in':\n",
    "            df = df.filter(col(filter['column']).isin(filter['value']))\n",
    "\n",
    "    df = df.group_by(request['group_by'])\n",
    "\n",
    "    aggs = []\n",
    "    for metric in request['metrics']:\n",
    "        if metric['function'] == 'sum':\n",
    "            aggs.append(sum(col(metric['column'])).alias(metric['name']))\n",
    "        elif metric['function'] == 'avg':\n",
    "            aggs.append(avg(col(metric['column'])).alias(metric['name']))\n",
    "        elif metric['function'] == 'count':\n",
    "            aggs.append(count(col(metric['column'])).alias(metric['name']))\n",
    "    df = df.agg(*aggs).with_column('created', to_char(current_timestamp(), 'YYYY-MM-DD HH24:MI:SS'))\n",
    "    \n",
    "    df.write.mode(\"overwrite\").save_as_table(request['target_table'])\n",
    "    \n",
    "    return f\"Aggregation completed. Results saved to {request['target_table']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from customfunctions.connection import SnowflakeConnection\n",
    "from snowflake.snowpark.version import VERSION\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No active session with get_active_session() moving to create_snowflake_session. Error Seen:\n",
      "(1403): No default Session is found. Please create a session before you call function 'udf' or use decorator '@udf'.\n",
      "\n",
      "Connection Established with the following parameters:\n",
      "Role                        : \"DATA_SCIENTIST\"\n",
      "Database                    : \"DATASCIENCE\"\n",
      "Schema                      : \"CUSTOM_FUNCTIONS\"\n",
      "Warehouse                   : \"DS_WH_XS\"\n",
      "Snowflake version           : 8.46.1\n",
      "Snowpark for Python version : 1.26.0\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "\n",
    "    # We can also use Snowpark for our analyses!\n",
    "    from snowflake.snowpark.context import get_active_session\n",
    "    session = get_active_session()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"No active session with get_active_session() moving to create_snowflake_session. Error Seen:\\n{e}\")\n",
    "    config = {\n",
    "        'user': os.getenv('SNOWFLAKE_USER', ''),\n",
    "        'password': os.getenv('SNOWFLAKE_PASSWORD', ''),\n",
    "        'account': os.getenv('SNOWFLAKE_ACCOUNT', ''),\n",
    "        'database': 'DATASCIENCE',\n",
    "        'warehouse': 'DS_WH_XS',\n",
    "        'schema': 'CUSTOM_FUNCTIONS',\n",
    "        'role': 'DATA_SCIENTIST'\n",
    "    }\n",
    "    sfc = SnowflakeConnection(**config)\n",
    "    session = sfc.get_session()\n",
    "    snowflake_environment = session.sql('SELECT current_user(), current_version()').collect()\n",
    "    snowpark_version = VERSION\n",
    "    print('\\nConnection Established with the following parameters:')\n",
    "    print('Role                        : {}'.format(session.get_current_role()))\n",
    "    print('Database                    : {}'.format(session.get_current_database()))\n",
    "    print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "    print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "    print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "    print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------\n",
      "|\"PRODUCT_CATEGORY\"  |\"REGION\"  |\"TOTAL_SALES\"  |\"AVERAGE_ORDER_VALUE\"  |\"ORDER_COUNT\"  |\"CREATED\"            |\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "|Electronics         |North     |121611.75      |502.2308764940239      |251            |2024-12-17 11:47:04  |\n",
      "|Sports              |South     |127182.67      |511.0550199203187      |251            |2024-12-17 11:47:04  |\n",
      "|Clothing            |South     |136309.18      |548.9966798418973      |253            |2024-12-17 11:47:04  |\n",
      "|Home                |South     |151382.34      |480.46474637681155     |276            |2024-12-17 11:47:04  |\n",
      "|Electronics         |East      |137977.52      |494.1362548262548      |259            |2024-12-17 11:47:04  |\n",
      "|Books               |West      |135392.85      |489.70191570881224     |261            |2024-12-17 11:47:04  |\n",
      "|Clothing            |West      |100747.99      |487.33851851851847     |216            |2024-12-17 11:47:04  |\n",
      "|Clothing            |East      |123848.65      |502.2717479674797      |246            |2024-12-17 11:47:04  |\n",
      "|Clothing            |North     |128602.42      |508.28915057915066     |259            |2024-12-17 11:47:04  |\n",
      "|Electronics         |South     |117874.55      |501.7482251082251      |231            |2024-12-17 11:47:04  |\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aggregation_request = json.dumps({\n",
    "    \"request_id\": \"AGG_001\",\n",
    "    \"source_table\": \"orders\",\n",
    "    \"target_table\": \"orders_aggregates\",\n",
    "    \"group_by\": [\"PRODUCT_CATEGORY\", \"REGION\"],\n",
    "    \"metrics\": [\n",
    "        {\"name\": \"TOTAL_SALES\", \"function\": \"sum\", \"column\": \"SALES_AMOUNT\"},\n",
    "        {\"name\": \"AVERAGE_ORDER_VALUE\", \"function\": \"avg\", \"column\": \"ORDER_VALUE\"},\n",
    "        {\"name\": \"ORDER_COUNT\", \"function\": \"count\", \"column\": \"ORDER_ID\"}\n",
    "    ],\n",
    "    \"filters\": [\n",
    "        {\"column\": \"DATE\", \"operator\": \"between\", \"value\": [\"2023-01-01\", \"2023-12-31\"]},\n",
    "        {\"column\": \"STATUS\", \"operator\": \"in\", \"value\": [\"completed\", \"shipped\"]}\n",
    "    ],\n",
    "    \"version\": \"1.0.0\"\n",
    "})\n",
    "\n",
    "perform_aggregation(session, aggregation_request)\n",
    "\n",
    "session.sql('SELECT * FROM orders_aggregates').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "custom_functions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
