{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# customfunctions\n",
    "\n",
    "> customfunctions POC Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Deployment Guide\n",
    "\n",
    "## 1. Installing Snowflake CLI\n",
    "\n",
    "[Link](https://docs.snowflake.com/en/developer-guide/snowflake-cli-v2/installation/installation)\n",
    "\n",
    "[Cheat Sheet](https://github.com/Snowflake-Labs/sf-cheatsheets/blob/main/snowflake-cli.md)\n",
    "\n",
    "To install the Snowflake CLI, follow the instructions provided in the official installation guide. This guide covers all the necessary steps to set up the CLI on your system.\n",
    "\n",
    "## 2. Configuring the CLI\n",
    "To use the Snowflake CLI, you need to create a connection configuration in the ~/.snowflake/config.toml file. This file allows you to specify connection details for various environments. Refer to the Snowflake CLI configuration documentation for a comprehensive guide.\n",
    "\n",
    "[Using Snowpark in Snowflake CLI](https://docs.snowflake.com/en/developer-guide/snowflake-cli-v2/snowpark/overview)\n",
    "\n",
    "## 3. Setting Up Your Database and Schema\n",
    "\n",
    "You can use the Snowsight UI or the Snowflake CLI to execute the following SQL commands. While the code example uses the ACCOUNTADMIN role for simplicity, you should use a role with the appropriate permissions in your environment.\n",
    "\n",
    "```sql\n",
    "ALTER SESSION SET query_tag = '{\"team\":\"Solutions\",\"name\":\"JeremyDemlow\", \"version\":0.1, \"attributes\":{\"medium\":\"setup\", \"source\":\"customfunctions\", \"purpose\": \"setup\"}}';\n",
    "\n",
    "USE ROLE ACCOUNTADMIN;\n",
    "CREATE ROLE customfunctions_USER_ROLE;\n",
    "\n",
    "USE ROLE SYSADMIN;\n",
    "GRANT CREATE DATABASE ON ACCOUNT TO ROLE customfunctions_USER_ROLE;\n",
    "GRANT CREATE WAREHOUSE ON ACCOUNT TO ROLE customfunctions_USER_ROLE;\n",
    "GRANT CREATE COMPUTE POOL ON ACCOUNT TO ROLE customfunctions_USER_ROLE;\n",
    "\n",
    "USE ROLE ACCOUNTADMIN;\n",
    "GRANT CREATE INTEGRATION ON ACCOUNT TO ROLE customfunctions_USER_ROLE;\n",
    "GRANT MONITOR USAGE ON ACCOUNT TO ROLE customfunctions_USER_ROLE;\n",
    "GRANT EXECUTE MANAGED TASK ON ACCOUNT TO ROLE customfunctions_USER_ROLE;\n",
    "GRANT BIND SERVICE ENDPOINT ON ACCOUNT TO ROLE customfunctions_USER_ROLE;\n",
    "GRANT IMPORTED PRIVILEGES ON DATABASE snowflake TO ROLE customfunctions_USER_ROLE;\n",
    "GRANT ROLE customfunctions_USER_ROLE TO USER JDEMLOW;\n",
    "GRANT ROLE customfunctions_USER_ROLE TO USER jd_service_account_admin;\n",
    "\n",
    "USE ROLE customfunctions_USER_ROLE;\n",
    "\n",
    "CREATE OR REPLACE WAREHOUSE customfunctions_WH\n",
    "  WAREHOUSE_SIZE = XSMALL\n",
    "  AUTO_SUSPEND = 120\n",
    "  AUTO_RESUME = TRUE;\n",
    "\n",
    "CREATE DATABASE customfunctions; \n",
    "CREATE SCHEMA DEV;\n",
    "CREATE SCHEMA UAT;\n",
    "CREATE SCHEMA PROD;\n",
    "USE SCHEMA DEV;\n",
    "```\n",
    "\n",
    "## 4. Initializing and Deploying the Snowpark Project\n",
    "\n",
    "### Creating a Boilerplate\n",
    "To set up a boilerplate Snowpark project, use the following command:\n",
    "\n",
    "```bash\n",
    "snow snowpark init customfunctions\n",
    "```\n",
    "> Note: The boilerplate structure can be customized. In this example, adjustments were made to rename the default 'app/' directory to 'customfunctions/' in the snowflake.yml file. You can modify these settings based on your preferences.\n",
    "\n",
    "### Building and Deploying the Project\n",
    "To build and deploy the Snowpark project, execute:\n",
    "\n",
    "```bash\n",
    "snow snowpark build; snow snowpark deploy --replace; rm customfunctions.zip\n",
    "```\n",
    "The deployment output will list the created objects, such as procedures and functions.\n",
    "\n",
    "## 5. Creating and Testing a Table\n",
    "\n",
    "### Creating a Fake Orders Table\n",
    "Navigate to the dev/development.ipynb notebook and run the cells to create a fake orders table in the DEV schema. This setup is essential for testing and development.\n",
    "\n",
    "> Note: Running the entire notebook will also perform an aggregation in the DEV schema. You can defer this step if you prefer to follow the next steps.\n",
    "\n",
    "### Testing Functions and Procedures\n",
    "To test the functions and procedures, use the following commands in Snowsight or the Snowflake CLI:\n",
    "\n",
    "```sql\n",
    "-- Procedures\n",
    "CALL customfunctions.DEV.HELLO_PROCEDURE('I would like a sandwich, please');\n",
    "CALL customfunctions.DEV.TEST_PROCEDURE();\n",
    "\n",
    "-- UDFs\n",
    "SELECT customfunctions.DEV.HELLO_FUNCTION(PRODUCT_CATEGORY) FROM customfunctions.DEV.ORDERS;\n",
    "Testing the Aggregation Procedure\n",
    "To test the perform_aggregation procedure, use the following SQL commands:\n",
    "```\n",
    "\n",
    "```sql\n",
    "CALL customfunctions.DEV.PERFORM_AGGREGATION(\n",
    "'{\n",
    "    \"request_id\": \"AGG_001\",\n",
    "    \"source_table\": \"orders\",\n",
    "    \"target_table\": \"orders_aggregates\",\n",
    "    \"group_by\": [\"PRODUCT_CATEGORY\", \"REGION\"],\n",
    "    \"metrics\": [\n",
    "        {\"name\": \"TOTAL_SALES\", \"function\": \"sum\", \"column\": \"SALES_AMOUNT\"},\n",
    "        {\"name\": \"AVERAGE_ORDER_VALUE\", \"function\": \"avg\", \"column\": \"ORDER_VALUE\"},\n",
    "        {\"name\": \"ORDER_COUNT\", \"function\": \"count\", \"column\": \"ORDER_ID\"}\n",
    "    ],\n",
    "    \"filters\": [\n",
    "        {\"column\": \"DATE\", \"operator\": \"between\", \"value\": [\"2023-01-01\", \"2023-12-31\"]},\n",
    "        {\"column\": \"STATUS\", \"operator\": \"in\", \"value\": [\"completed\", \"shipped\"]}\n",
    "    ],\n",
    "    \"version\": \"1.0.0\"\n",
    "}'\n",
    ");\n",
    "\n",
    "-- Using caller rights of the session, but using dev data and putting the results in uat\n",
    "CALL customfunctions.DEV.PERFORM_AGGREGATION(\n",
    "'{\n",
    "    \"request_id\": \"AGG_002\",\n",
    "    \"source_table\": \"customfunctions.dev.orders\",\n",
    "    \"target_table\": \"customfunctions.uat.orders_aggregates\",\n",
    "    \"group_by\": [\"PRODUCT_CATEGORY\", \"REGION\"],\n",
    "    \"metrics\": [\n",
    "        {\"name\": \"TOTAL_SALES\", \"function\": \"sum\", \"column\": \"SALES_AMOUNT\"},\n",
    "        {\"name\": \"AVERAGE_ORDER_VALUE\", \"function\": \"avg\", \"column\": \"ORDER_VALUE\"},\n",
    "        {\"name\": \"ORDER_COUNT\", \"function\": \"count\", \"column\": \"ORDER_ID\"}\n",
    "    ],\n",
    "    \"filters\": [\n",
    "        {\"column\": \"DATE\", \"operator\": \"between\", \"value\": [\"2023-01-01\", \"2023-12-31\"]},\n",
    "        {\"column\": \"STATUS\", \"operator\": \"in\", \"value\": [\"completed\", \"shipped\"]}\n",
    "    ],\n",
    "    \"version\": \"1.0.0\"\n",
    "}'\n",
    ");\n",
    "```\n",
    "This guide provides a streamlined approach to setting up and deploying your Snowflake environment with Snowpark. Customize as necessary to fit your project's requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW CHANGES & FUNCTIONS\n",
    "\n",
    "## 1. Download SQLALCHEMY\n",
    "\n",
    "```bash\n",
    "\n",
    "wget https://files.pythonhosted.org/packages/py3/s/snowflake_sqlalchemy/snowflake_sqlalchemy-1.5.3-py3-none-any.whl\n",
    "\n",
    "snow stage copy snowflake_sqlalchemy-1.5.3-py3-none-any.whl @customfunctions.DEV.CODE --overwrite\n",
    "```\n",
    "\n",
    "## 2. Deploy Snowpark Project\n",
    "\n",
    "```bash\n",
    "\n",
    "snow snowpark build; snow snowpark deploy --replace; rm customfunctions.zip; rm requirements.snowflake.txt\n",
    "\n",
    "customfunctions % snow snowpark build; snow snowpark deploy --replace; rm customfunctions.zip; rm requirements.snowflake.txt\n",
    "Build done. Artifact path: /Users/jdemlow/github/customfunctions/customfunctions.zip\n",
    "+----------------------------------------------------------------------------------------+\n",
    "| object                                                | type      | status             |\n",
    "|-------------------------------------------------------+-----------+--------------------|\n",
    "| customfunctions.DEV.hello_procedure(name string)                  | procedure | definition updated |\n",
    "| customfunctions.DEV.perform_aggregation(aggrequest string)        | procedure | definition updated |\n",
    "| customfunctions.DEV.test_procedure()                              | procedure | definition updated |\n",
    "| customfunctions.DEV.perform_aggregation_sqlach(aggrequest string) | procedure | created            |\n",
    "| customfunctions.DEV.hello_function(name string)                   | function  | definition updated |\n",
    "+----------------------------------------------------------------------------------------+\n",
    "```\n",
    "\n",
    "## Call Command With SqlAlchemy\n",
    "\n",
    "```sql\n",
    "\n",
    "CALL customfunctions.DEV.PERFORM_AGGREGATION_SQLACH(\n",
    "'{\n",
    "    \"request_id\": \"AGG_001\",\n",
    "    \"source_table\": \"orders\",\n",
    "    \"target_table\": \"customfunctions.prod.orders_aggregates\",\n",
    "    \"group_by\": [\"PRODUCT_CATEGORY\", \"REGION\"],\n",
    "    \"metrics\": [\n",
    "        {\"name\": \"TOTAL_SALES\", \"function\": \"sum\", \"column\": \"SALES_AMOUNT\"},\n",
    "        {\"name\": \"AVERAGE_ORDER_VALUE\", \"function\": \"avg\", \"column\": \"ORDER_VALUE\"},\n",
    "        {\"name\": \"ORDER_COUNT\", \"function\": \"count\", \"column\": \"ORDER_ID\"}\n",
    "    ],\n",
    "    \"filters\": [\n",
    "        {\"column\": \"DATE\", \"operator\": \"between\", \"value\": [\"2023-01-01\", \"2023-12-31\"]},\n",
    "        {\"column\": \"STATUS\", \"operator\": \"in\", \"value\": [\"completed\", \"shipped\"]}\n",
    "    ],\n",
    "    \"version\": \"1.0.0\"\n",
    "}'\n",
    ");\n",
    "\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Results\n",
    "Aggregation completed. Results saved to customfunctions.prod.orders_aggregates\n",
    "\n",
    "```\n",
    "\n",
    "> If you want to use snowflake notebooks please let me know and I will show you that method here, but this should be good to go now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
